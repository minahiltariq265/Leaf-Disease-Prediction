# -*- coding: utf-8 -*-
"""Leaf Disease Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/leaf-disease-prediction-af03d4fe-2c2f-4bed-bd05-d2f2c88be05d.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250103/auto/storage/goog4_request%26X-Goog-Date%3D20250103T151024Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D544d09c26060b1ac577829d5ad5e09c67ac7556ac4592ff23510bb234d0516aec77a760d2aecaa4bdd8a2df5e55636cbc87e1800582a20d18182c9c27f31f42fc7ef5f9ebe67083f7cb71e647ee9cf5e4bab05e90147213f2098c25015604d8596ead7e33744997fb6a7ef210ac06693125a83e816a2890fe8c75dda7c23338cb5697e0933c09a3894d8c859c59ce78eb5636643b0f4c3b1991fb600551a56d928c55920b9170ef9f430bf0f6c6e98f9252c459261c4d6460cf3fb190c8a2af3d617461e4e495792e61bf391f738a45b50ea3bae1ca54e5258d08e47ebc92d6c149b3cd552523017bec35179c2fbbad01ba75507043d981b5ebbfaefbb6dea66
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D
from sklearn.metrics import f1_score

# Labels Mapping
label_map = {0: "Healthy", 1: "Common Rust", 2: "Blight", 3: "Gray Leaf Spot"}
label_map_inv = {v: k for k, v in label_map.items()}

# Load Train Data
train_df = pd.read_csv("/kaggle/input/training-csv/train.csv")
train_df['Image'] = train_df['Image'].astype(str) + '.jpg'
train_df['Label'] = train_df['Label'].map(label_map)
print(train_df.head())
test_dir = "/kaggle/input/leaf-disease/data/test"
test_df = pd.DataFrame({
    "Image": os.listdir(test_dir)  # List all image filenames in the test directory
})
print(test_df)

# Data Generators for Augmentation
img_size = (224, 224)
batch_size = 32

datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=False,
    validation_split=0.2
)


train_gen = datagen.flow_from_dataframe(
    dataframe=train_df,
    directory="/kaggle/input/leaf-disease/data/train",
    x_col="Image",
    y_col="Label",
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="training"
)

val_gen = datagen.flow_from_dataframe(
    dataframe=train_df,
    directory="/kaggle/input/leaf-disease/data/train",
    x_col="Image",
    y_col="Label",
    target_size=img_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="validation"
)
test_datagen = ImageDataGenerator(rescale=1./255)  # Only normalization, no augmentation

test_gen = test_datagen.flow_from_dataframe(
    dataframe=test_df,                  # Test dataframe
    directory="/kaggle/input/leaf-disease/data/test",  # Test directory
    x_col="Image",                      # Column with image filenames
    y_col=None,                         # No labels for test set
    target_size=img_size,               # Resize to match model input size
    batch_size=batch_size,              # Batch size
    class_mode=None,                    # No labels for test set
    shuffle=False                       # Keep order consistent for predictions
)

#TESTINGGGGGGGGGGGGGGGG
from tensorflow.keras.applications import ResNet50

# Load ResNet50 without downloading weights
base_model = ResNet50(
    weights= "/kaggle/input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5",  # Avoid downloading weights
    include_top=False,
    input_shape=(224, 224, 3)
)
# Freeze the base model to retain pre-trained weights
#base_model.trainable = False
base_model.trainable = True
for layer in base_model.layers[:-50]:  # Freeze all layers except the last 50
    layer.trainable = False
# Add custom layers on top of the pre-trained model
x = base_model.output
x = GlobalAveragePooling2D()(x)  # Reduce dimensions
x = Dense(256, activation="relu")(x)  # Fully connected layer
x = Dense(4, activation="softmax")(x)  # Output layer (4 classes)

# Create the complete model
model = Model(inputs=base_model.input, outputs=x)

from tensorflow.keras.metrics import Recall, Precision
model.compile(
    optimizer=Adam(learning_rate=0.01),
    loss='categorical_crossentropy',
    metrics=['accuracy', Recall(), Precision()]
)

# Check for Class Imbalance
from sklearn.utils import compute_class_weight
class_weights = compute_class_weight(
    class_weight="balanced",
    classes=np.unique(train_df['Label']),
    y=train_df['Label']
)
class_weights = dict(enumerate(class_weights))
print(class_weights)

# Train the Model
history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=100,
    class_weight = class_weights
)

# Evaluate on Validation Data
val_loss, val_acc, val_recall, val_precision = model.evaluate(val_gen)
#val_loss, val_acc = model.evaluate(val_gen)
print(f"Validation Accuracy: {val_acc:.2f}")

# Calculate F2 score
f2_score = (5 * val_precision * val_recall) / (4 * val_precision + val_recall)
print(f"Validation Accuracy: {val_acc:.2f}")
print(f"Validation Recall: {val_recall:.2f}")
print(f"Validation Precision: {val_precision:.2f}")
print(f"Validation F2 Score: {f2_score:.2f}")

test_data = []  # Initialize as a list

# Use test_df['Image'] which contains the image filenames
for img_path in test_df["Image"]:
    img = tf.keras.utils.load_img(f"/kaggle/input/leaf-disease/data/test/{img_path}", target_size=img_size)
    img_array = tf.keras.utils.img_to_array(img) / 255.0
    test_data.append(img_array)

test_data = np.array(test_data)  # Convert to NumPy array

predictions = model.predict(test_data)
predicted_labels = np.argmax(predictions, axis=1)

submission_df = pd.DataFrame({
    "Image": test_df["Image"],
    "Predicted": predicted_labels
})

# Extract the numeric part of the image name and sort based on it
submission_df["ImageNumber"] = submission_df["Image"].str.extract(r'(\d+)').astype(int)
submission_df.sort_values("ImageNumber", inplace=True)

# Drop the helper column used for sorting
submission_df.drop(columns=["ImageNumber"], inplace=True)

# Save the sorted DataFrame to a CSV file
submission_df.to_csv("/kaggle/working/submission.csv", index=False)

print("Submission file created and sorted!")

from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# Predict on validation set
val_predictions = model.predict(val_gen)
predicted_classes = np.argmax(val_predictions, axis=1)
true_classes = val_gen.classes

# Confusion matrix
conf_matrix = confusion_matrix(true_classes, predicted_classes)
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=label_map.values(), yticklabels=label_map.values())
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

# Classification report
print(classification_report(true_classes, predicted_classes, target_names=label_map.values()))